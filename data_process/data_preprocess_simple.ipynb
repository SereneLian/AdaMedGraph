{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "# add outcomes\n",
    "outcomes=pd.read_csv(path+'PD_Outcome.csv')[['PATNO','EVENT_ID', 'INFODT', 'HY']]\n",
    "outcomes['INFODT'] = pd.to_datetime(outcomes['INFODT'])\n",
    "print('original len:',len(outcomes))\n",
    "# add tabular features\n",
    "pd_patients=pd.read_csv(path+'pd_on.csv')\n",
    "pd_patients=pd_patients.replace({'UR': pd.NA})\n",
    "# basic features\n",
    "demo = pd.read_csv(path+'demographics.csv')\n",
    "# medication\n",
    "ledd = pd.read_csv(path+'ledd_new.csv')\n",
    "# gene \n",
    "gene = pd.read_csv(path+'genes.csv')\n",
    "mri = pd.read_csv(path+'mri_segments.csv')\n",
    "# combine basic and outcomes\n",
    "outcomes=outcomes.merge(demo[['PATNO', 'ENROLL_AGE', 'SEX']], on='PATNO', how= 'inner')\n",
    "outcomes=outcomes.replace({'UR': pd.NA})\n",
    "print('after merging len:',len(outcomes))\n",
    "\n",
    "# combine tarbular and medication information\n",
    "pd_patients = pd_patients.merge(ledd, on = ['PATNO','EVENT_ID', 'INFODT'], how ='inner')\n",
    "hc = pd.read_csv(path+'hc.csv')\n",
    "len(pd_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select BL, M12, M24 and M36 timeslots for features!!!\n",
    "target_evnents =['BL', 'SC', 'V04', 'V06', 'V08'] # select 12 month(we do not need features from 12 month) \n",
    "bs_patients =pd_patients[pd_patients['EVENT_ID'].isin(target_evnents)]\n",
    "print(len(bs_patients))\n",
    "bs_patients.drop_duplicates(subset=['PATNO', 'EVENT_ID', 'INFODT'], keep='last', inplace=True)\n",
    "print(len(bs_patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_hc =hc[hc['EVENT_ID'].isin(target_evnents)]\n",
    "print(len(bs_hc))\n",
    "bs_hc.drop_duplicates(subset=['PATNO', 'EVENT_ID', 'INFODT'], keep='last', inplace=True)\n",
    "print(len(bs_hc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge SC and BL features\n",
    "def sc_bl_imputation(bs_patients):\n",
    "    uni_idx = set(bs_patients['PATNO'])\n",
    "    BL_event = ['BL', 'SC']\n",
    "    other_event =  ['V04', 'V06', 'V08',]\n",
    "    new_bs_patients=pd.DataFrame(columns=bs_patients.columns)\n",
    "    counts = []\n",
    "    for idx in uni_idx:\n",
    "        #for BL and SC\n",
    "        df = bs_patients[bs_patients['PATNO']==idx]\n",
    "        tar_df = df[df['EVENT_ID'].isin(BL_event)]\n",
    "        tar_df['INFODT']= pd.to_datetime(tar_df['INFODT'])\n",
    "        tar_df.sort_values(by='INFODT',ascending=True,inplace=True)\n",
    "        tar_df = tar_df.fillna(method='ffill') # use SC information to fill BL\n",
    "        tar_df = tar_df.fillna(method='bfill') # use SC information to fill BL\n",
    "        # for other evetnts\n",
    "        other_tar = df[df['EVENT_ID'].isin(other_event)]\n",
    "        new_bs_patients = pd.concat([new_bs_patients,tar_df])\n",
    "        new_bs_patients = pd.concat([new_bs_patients,other_tar])\n",
    "        counts.append(len(tar_df))\n",
    "    print(len(new_bs_patients))\n",
    "    new_bs_patients = new_bs_patients[new_bs_patients.EVENT_ID.isin(['BL','V04', 'V06', 'V08'])]\n",
    "    print(len(new_bs_patients))\n",
    "    return new_bs_patients\n",
    "\n",
    "new_bs_patients = sc_bl_imputation(bs_patients)\n",
    "new_bs_hc = sc_bl_imputation(bs_hc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before data inputation, we need to check the label missing rate\n",
    "def missing_check(new_bs_patients, merge = True):\n",
    "    middle_tar=['NP1RTOT','NP1PTOT','NP2PTOT','NP3TOT', 'NHY','MoCA_score','ESS_TOT']\n",
    "    bs_patients_tar = new_bs_patients[middle_tar]\n",
    "    bs_patients_tar['label_missing'] = bs_patients_tar.isna().sum(axis=1)\n",
    "    bs_patients_tar['label_missing'].value_counts()\n",
    "    bs_patients_tar = bs_patients_tar[bs_patients_tar['label_missing']<=3]\n",
    "    new_bs_patients = new_bs_patients[new_bs_patients.index.isin(bs_patients_tar.index)]\n",
    "    # print(len(new_bs_patients))\n",
    "    # adding sex and age\n",
    "    if merge:\n",
    "        new_bs_patients = new_bs_patients.merge(outcomes[['PATNO', 'EVENT_ID', 'ENROLL_AGE', 'SEX']], on=['PATNO', 'EVENT_ID'], how='inner')\n",
    "    new_bs_patients.drop_duplicates(inplace=True)\n",
    "    print(len(new_bs_patients))\n",
    "    return new_bs_patients\n",
    "\n",
    "new_bs_patients = missing_check(new_bs_patients)\n",
    "\n",
    "new_bs_hc = missing_check(new_bs_hc, False)\n",
    "new_bs_hc = new_bs_hc[new_bs_hc['NHY']==str(0)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select features and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_cols = [\n",
    "'PATNO',\n",
    "'EVENT_ID',\n",
    "'ENROLL_AGE',\n",
    "'SEX',\n",
    "'INFODT',\n",
    "'NP1COG',\n",
    "'NP1HALL',\n",
    "'NP1DPRS',\n",
    "'NP1ANXS',\n",
    "'NP1APAT',\n",
    "'NP1DDS',\n",
    "'NP1SLPN',\n",
    "'NP1SLPD',\n",
    "'NP1PAIN',\n",
    "'NP1URIN',\n",
    "'NP1CNST',\n",
    "'NP1LTHD', # U1 scores\n",
    "'NP1FATG',\n",
    "'NP2SPCH',\n",
    "'NP2SALV',\n",
    "'NP2SWAL',\n",
    "'NP2EAT',\n",
    "'NP2DRES',\n",
    "'NP2HYGN',\n",
    "'NP2HWRT',\n",
    "'NP2HOBB',\n",
    "'NP2TURN',\n",
    "'NP2TRMR',\n",
    "'NP2RISE',\n",
    "'NP2WALK',\n",
    "'NP2FREZ', # u2 scores\n",
    "'MSEADLG', # Modifier S and E overall score\n",
    "'NHY', # U3 3.21\n",
    "'NP3SPCH',\n",
    "'NP3FACXP',\n",
    "'NP3RIGN',\n",
    "'NP3RIGRU',\n",
    "'NP3RIGLU',\n",
    "'NP3RIGRL',\n",
    "'NP3RIGLL',\n",
    "'NP3FTAPR',\n",
    "'NP3FTAPL',\n",
    "'NP3HMOVR',\n",
    "'NP3HMOVL',\n",
    "'NP3PRSPR',\n",
    "'NP3PRSPL',\n",
    "'NP3TTAPR',\n",
    "'NP3TTAPL',\n",
    "'NP3LGAGR',\n",
    "'NP3LGAGL',\n",
    "'NP3RISNG',\n",
    "'NP3GAIT',\n",
    "'NP3FRZGT',\n",
    "'NP3PSTBL',\n",
    "'NP3POSTR',\n",
    "'NP3BRADY',\n",
    "'NP3PTRMR',\n",
    "'NP3PTRML',\n",
    "'NP3KTRMR',\n",
    "'NP3KTRML',\n",
    "'NP3RTARU',\n",
    "'NP3RTALU',\n",
    "'NP3RTARL',\n",
    "'NP3RTALL',\n",
    "'NP3RTALJ',\n",
    "'NP3RTCON',\n",
    "'NP3TOT',\n",
    "'SDMTOTAL', # Symbol Digit Modalities,  Neuropsychological Test, tot\n",
    "'STAI_TOT', # State-Trait Anxiety Inventory for Adults tot \n",
    "'SFT_TOT', # Semantic Fluency tot\n",
    "'SCOPA_AUT_TOT', #SCOPA-AUT, autonomic test, Lower score means better.\n",
    "'REMSLEEP_TOT', # REM Sleep Behavior Questionnaire\n",
    "'QUIP_A', # This is a questionnaire about gambling, buying, etc. It is a nerobehavioral questionnaire.\n",
    "'QUIP_B',\n",
    "'QUIP_C',\n",
    "'QUIP_D',\n",
    "'QUIP_E',\n",
    "# 'UPSIT_TOT', # University_of_Pennsylvania_Smell_Identification_Test__UPSIT\n",
    "'MoCA_score',\n",
    "'LNS_TOT', # Letter Number Sequencing, total score\n",
    "'HVLT_TOT_Recall', # Hopkins Verbal Learning Test， HVLT Immediate/Total Recall\tSum of HVLTRT1 - HVLTRT3\n",
    "'HVLT_DCR_REC',\n",
    "'HVLT_RETENTION',\n",
    "'GDS_TOT', # The Geriatric Depression Scale (GDS) is a 30-item self-report assessment used to identify depression \n",
    "'GDS_Depressed', # if GDS tot >5\n",
    "'ESS_TOT', # Epworth Sleepiness Scale\n",
    "'ESS_Sleepy', # if ESS_ToT>10\n",
    "'BJLOT_TOT', #  Benton Judgement of Line Orientation total score\n",
    "'DATSCAN_CAUDATE_R', # 'CAUDATE_R',\n",
    "'DATSCAN_CAUDATE_L', # 'CAUDATE_L',\n",
    "'DATSCAN_PUTAMEN_R',# 'PUTAMEN_R',\n",
    "'DATSCAN_PUTAMEN_L',# 'PUTAMEN_L']\n",
    "# analysis tagets\n",
    "'NP1RTOT',\n",
    "'NP1PTOT',\n",
    "'NP2PTOT',\n",
    "'LEDD'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(interest_cols))\n",
    "print(len(set(interest_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_cols = [\n",
    "'PATNO',\n",
    "'EVENT_ID',\n",
    "'ENROLL_AGE',\n",
    "'SEX',\n",
    "'INFODT',\n",
    "'NP1COG',\n",
    "'NP1HALL',\n",
    "'NP1DPRS',\n",
    "'NP1ANXS',\n",
    "'NP1APAT',\n",
    "'NP1DDS',\n",
    "'NP1SLPN',\n",
    "'NP1SLPD',\n",
    "'NP1PAIN',\n",
    "'NP1URIN',\n",
    "'NP1CNST',\n",
    "'NP1LTHD', # U1 scores\n",
    "'NP1FATG',\n",
    "'NP2SPCH',\n",
    "'NP2SALV',\n",
    "'NP2SWAL',\n",
    "'NP2EAT',\n",
    "'NP2DRES',\n",
    "'NP2HYGN',\n",
    "'NP2HWRT',\n",
    "'NP2HOBB',\n",
    "'NP2TURN',\n",
    "'NP2TRMR',\n",
    "'NP2RISE',\n",
    "'NP2WALK',\n",
    "'NP2FREZ', # u2 scores\n",
    "'MSEADLG', # Modifier S and E overall score\n",
    "'NHY', # U3 3.21\n",
    "'NP3SPCH',\n",
    "'NP3FACXP',\n",
    "'NP3RIGN',\n",
    "'NP3RIGRU',\n",
    "'NP3RIGLU',\n",
    "'NP3RIGRL',\n",
    "'NP3RIGLL',\n",
    "'NP3FTAPR',\n",
    "'NP3FTAPL',\n",
    "'NP3HMOVR',\n",
    "'NP3HMOVL',\n",
    "'NP3PRSPR',\n",
    "'NP3PRSPL',\n",
    "'NP3TTAPR',\n",
    "'NP3TTAPL',\n",
    "'NP3LGAGR',\n",
    "'NP3LGAGL',\n",
    "'NP3RISNG',\n",
    "'NP3GAIT',\n",
    "'NP3FRZGT',\n",
    "'NP3PSTBL',\n",
    "'NP3POSTR',\n",
    "'NP3BRADY',\n",
    "'NP3PTRMR',\n",
    "'NP3PTRML',\n",
    "'NP3KTRMR',\n",
    "'NP3KTRML',\n",
    "'NP3RTARU',\n",
    "'NP3RTALU',\n",
    "'NP3RTARL',\n",
    "'NP3RTALL',\n",
    "'NP3RTALJ',\n",
    "'NP3RTCON',\n",
    "'NP3TOT',\n",
    "'SDMTOTAL', # Symbol Digit Modalities,  Neuropsychological Test, tot\n",
    "'STAI_TOT', # State-Trait Anxiety Inventory for Adults tot \n",
    "'SFT_TOT', # Semantic Fluency tot\n",
    "'SCOPA_AUT_TOT', #SCOPA-AUT, autonomic test, Lower score means better.\n",
    "'REMSLEEP_TOT', # REM Sleep Behavior Questionnaire\n",
    "'QUIP_A', # This is a questionnaire about gambling, buying, etc. It is a nerobehavioral questionnaire.\n",
    "'QUIP_B',\n",
    "'QUIP_C',\n",
    "'QUIP_D',\n",
    "'QUIP_E',\n",
    "# 'UPSIT_TOT', # University_of_Pennsylvania_Smell_Identification_Test__UPSIT\n",
    "'MoCA_score',\n",
    "'LNS_TOT', # Letter Number Sequencing, total score\n",
    "'HVLT_TOT_Recall', # Hopkins Verbal Learning Test， HVLT Immediate/Total Recall\tSum of HVLTRT1 - HVLTRT3\n",
    "'HVLT_DCR_REC',\n",
    "'HVLT_RETENTION',\n",
    "'GDS_TOT', # The Geriatric Depression Scale (GDS) is a 30-item self-report assessment used to identify depression \n",
    "'GDS_Depressed', # if GDS tot >5\n",
    "'ESS_TOT', # Epworth Sleepiness Scale\n",
    "'ESS_Sleepy', # if ESS_ToT>10\n",
    "'BJLOT_TOT', #  Benton Judgement of Line Orientation total score\n",
    "'DATSCAN_CAUDATE_R', # 'CAUDATE_R',\n",
    "'DATSCAN_CAUDATE_L', # 'CAUDATE_L',\n",
    "'DATSCAN_PUTAMEN_R',# 'PUTAMEN_R',\n",
    "'DATSCAN_PUTAMEN_L',# 'PUTAMEN_L']\n",
    "# analysis tagets\n",
    "'NP3_Akinetic_Rigid',\n",
    "'NP3_Axial',\n",
    "'NP3_Tremor',\n",
    "'NP1TOT',\n",
    "'NP2PTOT',\n",
    "'NPTOT',\n",
    "'LEDD'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "'NP1COG',\n",
    "'NP1HALL',\n",
    "'NP1DPRS',\n",
    "'NP1ANXS',\n",
    "'NP1APAT',\n",
    "'NP1DDS',\n",
    "'NP1SLPN',\n",
    "'NP1SLPD',\n",
    "'NP1PAIN',\n",
    "'NP1URIN',\n",
    "'NP1CNST',\n",
    "'NP1LTHD', # U1 scores\n",
    "'NP1FATG',\n",
    "'NP2SPCH',\n",
    "'NP2SALV',\n",
    "'NP2SWAL',\n",
    "'NP2EAT',\n",
    "'NP2DRES',\n",
    "'NP2HYGN',\n",
    "'NP2HWRT',\n",
    "'NP2HOBB',\n",
    "'NP2TURN',\n",
    "'NP2TRMR',\n",
    "'NP2RISE',\n",
    "'NP2WALK',\n",
    "'NP2FREZ', # u2 scores\n",
    "'MSEADLG', # Modifier S and E overall score\n",
    "'NHY', # U3 3.21\n",
    "'NP3SPCH',\n",
    "'NP3FACXP',\n",
    "'NP3RIGN',\n",
    "'NP3RIGRU',\n",
    "'NP3RIGLU',\n",
    "'NP3RIGRL',\n",
    "'NP3RIGLL',\n",
    "'NP3FTAPR',\n",
    "'NP3FTAPL',\n",
    "'NP3HMOVR',\n",
    "'NP3HMOVL',\n",
    "'NP3PRSPR',\n",
    "'NP3PRSPL',\n",
    "'NP3TTAPR',\n",
    "'NP3TTAPL',\n",
    "'NP3LGAGR',\n",
    "'NP3LGAGL',\n",
    "'NP3RISNG',\n",
    "'NP3GAIT',\n",
    "'NP3FRZGT',\n",
    "'NP3PSTBL',\n",
    "'NP3POSTR',\n",
    "'NP3BRADY',\n",
    "'NP3PTRMR',\n",
    "'NP3PTRML',\n",
    "'NP3KTRMR',\n",
    "'NP3KTRML',\n",
    "'NP3RTARU',\n",
    "'NP3RTALU',\n",
    "'NP3RTARL',\n",
    "'NP3RTALL',\n",
    "'NP3RTALJ',\n",
    "'NP3RTCON',\n",
    "'NP3TOT',\n",
    "'SDMTOTAL', # Symbol Digit Modalities,  Neuropsychological Test, tot\n",
    "'STAI_TOT', # State-Trait Anxiety Inventory for Adults tot \n",
    "'SFT_TOT', # Semantic Fluency tot\n",
    "'SCOPA_AUT_TOT', #SCOPA-AUT, autonomic test, Lower score means better.\n",
    "'REMSLEEP_TOT', # REM Sleep Behavior Questionnaire\n",
    "'QUIP_A', # This is a questionnaire about gambling, buying, etc. It is a nerobehavioral questionnaire.\n",
    "'QUIP_B',\n",
    "'QUIP_C',\n",
    "'QUIP_D',\n",
    "'QUIP_E',\n",
    "# 'UPSIT_TOT', # University_of_Pennsylvania_Smell_Identification_Test__UPSIT\n",
    "'MoCA_score',\n",
    "'LNS_TOT', # Letter Number Sequencing, total score\n",
    "'HVLT_TOT_Recall', # Hopkins Verbal Learning Test， HVLT Immediate/Total Recall\tSum of HVLTRT1 - HVLTRT3\n",
    "'HVLT_DCR_REC',\n",
    "'HVLT_RETENTION',\n",
    "'GDS_TOT', # The Geriatric Depression Scale (GDS) is a 30-item self-report assessment used to identify depression \n",
    "'GDS_Depressed', # if GDS tot >5\n",
    "'ESS_TOT', # Epworth Sleepiness Scale\n",
    "'ESS_Sleepy', # if ESS_ToT>10\n",
    "'BJLOT_TOT', #  Benton Judgement of Line Orientation total score\n",
    "'DATSCAN_CAUDATE_R', # 'CAUDATE_R',\n",
    "'DATSCAN_CAUDATE_L', # 'CAUDATE_L',\n",
    "'DATSCAN_PUTAMEN_R',# 'PUTAMEN_R',\n",
    "'DATSCAN_PUTAMEN_L',# 'PUTAMEN_L']\n",
    "# analysis tagets\n",
    "'NP3_Akinetic_Rigid',\n",
    "'NP3_Axial',\n",
    "'NP3_Tremor',\n",
    "'NP1TOT',\n",
    "'NP2PTOT',\n",
    "'NPTOT',\n",
    "'LEDD',\n",
    "'PRS90',\n",
    "'GBA',\n",
    "'LRRK2',\n",
    "'SNCA',\n",
    "'APOE_E4'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar=[\n",
    "'NP1TOT',\n",
    "'NP2PTOT',\n",
    "'NP3TOT',    \n",
    "'NPTOT',\n",
    "'NP3_Axial',\n",
    "'NP3_Tremor',\n",
    "'NP3_Akinetic_Rigid',\n",
    "'NHY',\n",
    "'MoCA_score',\n",
    "'ESS_TOT'\n",
    "]\n",
    "\n",
    "reg_tar=[\n",
    "'NP1TOT',\n",
    "'NP2PTOT',\n",
    "'NP3TOT',    \n",
    "'NPTOT',\n",
    "'NP3_Axial',\n",
    "'NP3_Tremor',\n",
    "'NP3_Akinetic_Rigid',\n",
    "'MoCA_score',\n",
    "'ESS_TOT'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna with mean data\n",
    "def mean_fill(df, fill=False):\n",
    "    mr = []\n",
    "    clos = []\n",
    "    new_df = pd.DataFrame()\n",
    "    for column in interest_cols:\n",
    "        if column not in ['PATNO', 'EVENT_ID', 'ENROLL_AGE', 'SEX','INFODT', 'LEDD']:\n",
    "            missing_rate = df[column].isnull().sum()/len(df)\n",
    "            mr.append(missing_rate)\n",
    "            clos.append(column)\n",
    "            new_df[column] = pd.to_numeric(df[column])\n",
    "            if fill:\n",
    "                mean_val = int(df[column].mean())\n",
    "                df[column].fillna(mean_val, inplace=True)\n",
    "        else:\n",
    "            new_df[column] = df[column]\n",
    "    rec_df = pd.DataFrame()\n",
    "    rec_df['feature'] = clos\n",
    "    rec_df['missing'] = mr\n",
    "    return new_df, rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna with mean data\n",
    "def mean_fill_hc(df, fill=False):\n",
    "    mr = []\n",
    "    clos = []\n",
    "    for column in interest_cols:\n",
    "        if column not in ['PATNO', 'EVENT_ID', 'ENROLL_AGE', 'SEX','INFODT', 'LEDD']:\n",
    "            missing_rate = df[column].isnull().sum()/len(df)\n",
    "            mr.append(missing_rate)\n",
    "            clos.append(column)\n",
    "            df[column] = pd.to_numeric(df[column])\n",
    "            if fill:\n",
    "                mean_val = int(df[column].mean())\n",
    "                df[column].fillna(mean_val, inplace=True)\n",
    "    rec_df = pd.DataFrame()\n",
    "    rec_df['feature'] = clos\n",
    "    rec_df['missing'] = mr\n",
    "    return df, rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_patients_new, missing_pa = mean_fill(new_bs_patients)\n",
    "bs_hc_new, missing_hc = mean_fill_hc(new_bs_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_new_target(bs_patients_new):\n",
    "    bs_patients_new['NP1TOT'] = bs_patients_new['NP1RTOT'].astype(float)+bs_patients_new['NP1PTOT'].astype(float)\n",
    "    bs_patients_new['NPTOT'] = bs_patients_new['NP1RTOT'].astype(float)+bs_patients_new['NP1PTOT'].astype(float)+ bs_patients_new['NP2PTOT'].astype(float)+bs_patients_new['NP3TOT'].astype(float)\n",
    "    # jiangzhi\n",
    "    bs_patients_new['NP3_Rigidity']=bs_patients_new['NP3RIGLL'].astype(float)+bs_patients_new['NP3RIGLU'].astype(float)+bs_patients_new['NP3RIGN'].astype(float)+bs_patients_new['NP3RIGRL'].astype(float)+bs_patients_new['NP3RIGRU'].astype(float)\n",
    "    # zhenchan\n",
    "    bs_patients_new['NP3_RestTremer'] = bs_patients_new['NP3RTALJ'].astype(float)+bs_patients_new['NP3RTALL'].astype(float)+bs_patients_new['NP3RTALU'].astype(float)+bs_patients_new['NP3RTARL'].astype(float)+bs_patients_new['NP3RTARU'].astype(float)\n",
    "    bs_patients_new['NP3_Axial'] =bs_patients_new['NP3RISNG'].astype(float)+bs_patients_new['NP3GAIT'].astype(float)+bs_patients_new['NP3FRZGT'].astype(float)+bs_patients_new['NP3PSTBL'].astype(float)+bs_patients_new['NP3POSTR'].astype(float)+bs_patients_new['NP3BRADY'].astype(float)\n",
    "    bs_patients_new['NP3_Tremor']=bs_patients_new['NP3PTRMR'].astype(float)+bs_patients_new['NP3PTRML'].astype(float)+bs_patients_new['NP3KTRML'].astype(float)+bs_patients_new['NP3KTRMR'].astype(float)+bs_patients_new['NP3_RestTremer'].astype(float)+bs_patients_new['NP3RTCON'].astype(float)\n",
    "    bs_patients_new['NP3_Akinetic_Rigid'] = bs_patients_new['NP3FACXP'].astype(float)+bs_patients_new['NP3_Rigidity']+bs_patients_new['NP3FTAPR'].astype(float)+bs_patients_new['NP3FTAPL'].astype(float)+bs_patients_new['NP3HMOVR'].astype(float)+bs_patients_new['NP3HMOVL'].astype(float)+bs_patients_new['NP3PRSPL'].astype(float)+bs_patients_new['NP3PRSPR'].astype(float)+bs_patients_new['NP3TTAPL'].astype(float)+bs_patients_new['NP3TTAPR'].astype(float)+bs_patients_new['NP3LGAGL'].astype(float)+bs_patients_new['NP3LGAGR'].astype(float)\n",
    "    return bs_patients_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_patients_new = add_new_target(bs_patients_new)\n",
    "bs_hc_new = add_new_target(new_bs_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_patients_new = bs_patients_new[bs_patients_new.PATNO.isin(gene.PATNO)]\n",
    "print(len(bs_patients_new))\n",
    "print(len(set(bs_patients_new.PATNO)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_differ_hc(bs_patients_new,  env ='V04', tar=tar):\n",
    "        for col in tar:\n",
    "                bs_patients_new[col]=pd.to_numeric(bs_patients_new[col])\n",
    "        sp = set(bs_patients_new.PATNO)\n",
    "        envlist = ['BL', env]\n",
    "        new_out = []\n",
    "        for eid in sp:\n",
    "                pr = bs_patients_new[bs_patients_new.PATNO==eid]\n",
    "                pr = pr[pr.EVENT_ID.isin(envlist)]\n",
    "                # here pre should larger than 1\n",
    "                if len(pr) ==2:\n",
    "                        current_vist = pr[pr.EVENT_ID=='BL']\n",
    "                        next_vist = pr[pr.EVENT_ID==env]\n",
    "                        next_labels = next_vist[tar]\n",
    "                        # print(next_labels)\n",
    "                        current_labels = current_vist[tar]\n",
    "                        # print(current_labels)\n",
    "                        targets = next_labels.values[0]- current_labels.values[0]\n",
    "                        new_out.append(targets)\n",
    "        return new_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envss = 'V04'\n",
    "hc_data = events_differ_hc(bs_hc_new,  env =envss, tar=tar)\n",
    "new_tar = [\"Change_\"+t for t in tar]\n",
    "hc_s =pd.DataFrame(hc_data,columns= new_tar)\n",
    "print(len(hc_s))\n",
    "df=hc_s\n",
    "print(len(df))\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_patients_new.to_csv(path+'/data/PPMI_pd_M0_36.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set rule: next visit must be one year difference\n",
    "def events_differ(bs_patients_new,  env ='V04', tar=tar, interest_cols = new_feature_cols):\n",
    "        sp = set(bs_patients_new.PATNO)\n",
    "        envlist = ['BL', env]\n",
    "        new_out = []\n",
    "        for eid in sp:\n",
    "                pr = bs_patients_new[bs_patients_new.PATNO==eid]\n",
    "                pr = pr[pr.EVENT_ID.isin(envlist)]\n",
    "                # here pre should larger than 1\n",
    "                if len(pr) ==2:\n",
    "                        current_vist = pr[pr.EVENT_ID=='BL']\n",
    "                        data = current_vist[interest_cols].values[0]\n",
    "                        next_vist = pr[pr.EVENT_ID==env]\n",
    "                        next_labels = next_vist[tar]\n",
    "                        # print(next_labels)\n",
    "                        current_labels = current_vist[tar]\n",
    "                        # print(current_labels)\n",
    "                        \n",
    "                        targets = next_labels.values[0]-current_labels.values[0]\n",
    "                        data= [*data , *targets]\n",
    "                        new_out.append(data)\n",
    "        return new_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_tar = [\"Change_\"+t for t in tar]\n",
    "new_tar_reg = [\"Change_\"+t for t in reg_tar]\n",
    "data = events_differ(bs_patients_new,  env = envss, tar=tar)\n",
    "pd_patients_all =pd.DataFrame(data,columns= new_feature_cols+new_tar)\n",
    "pd_patients_all.drop_duplicates(inplace=True)\n",
    "pd_patients_all.describe().to_csv('results/ppmi_descri_pd_12month.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_patients_all = pd_patients_all.merge(gene, on = 'PATNO', how='inner')\n",
    "print(len(pd_patients_all))\n",
    "print(len(set(pd_patients_all.PATNO)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add MRI here\n",
    "pd_patients_all = pd_patients_all.merge(mri, on = 'PATNO', how='left')\n",
    "print(len(pd_patients_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_patients_all.isna().sum(axis=0).to_csv('results/pd_12month_missing_raw.csv')\n",
    "hc_s.isna().sum(axis=0).to_csv('results/hc_12month_missing_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes_list = []\n",
    "for i in range(axes.shape[0]):\n",
    "    for j in range(axes.shape[1]):\n",
    "        axes_list.append(axes[i, j])\n",
    "\n",
    "for i in range(len(axes_list)):\n",
    "    ax = axes_list[i]\n",
    "    hc_s[new_tar_reg[i]].plot(kind='hist', ax =ax, legend=new_tar_reg[i])\n",
    "fig.savefig('results/hc_12.png', dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes_list = []\n",
    "for i in range(axes.shape[0]):\n",
    "    for j in range(axes.shape[1]):\n",
    "        axes_list.append(axes[i, j])\n",
    "\n",
    "for i in range(len(axes_list)):\n",
    "    ax = axes_list[i]\n",
    "    pd_patients_all[new_tar_reg[i]].plot(kind='hist', ax =ax, legend=new_tar_reg[i])\n",
    "fig.savefig('results/pd_12.png', dpi=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func_pos(datas, thr_mean, thr_std, k=1):\n",
    "    labels =[]\n",
    "    for data in datas:\n",
    "    # the smaller the better \n",
    "        if data<(thr_mean-k*thr_std):\n",
    "            label=0\n",
    "        elif (thr_mean-k*thr_std) <= data <=(thr_mean+k*thr_std):\n",
    "            label=1\n",
    "        else:\n",
    "            label = 2\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def label_func_neg(datas, thr_mean, thr_std, k=1):\n",
    "    labels =[]\n",
    "    for data in datas:\n",
    "    # the larger the better \n",
    "        if data<(thr_mean-k*thr_std):\n",
    "            label=2\n",
    "        elif (thr_mean-k*thr_std) <= data <=(thr_mean+k*thr_std):\n",
    "            label=1\n",
    "        elif pd.isna(data):\n",
    "            label = pd.NA\n",
    "        else:\n",
    "            label = 0\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def label_func_hy(data):\n",
    "    # the smaller the better \n",
    "    if data<0:\n",
    "        label=0\n",
    "    elif data ==0:\n",
    "        label = 1\n",
    "    elif pd.isna(data):\n",
    "            label = pd.NA\n",
    "    else:\n",
    "        label=2\n",
    "    return label\n",
    "\n",
    "label_tar = [\"Label_\"+t for t in tar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "pd_patients_all['Label_NP1TOT'] = label_func_pos(pd_patients_all['Change_NP1TOT'], h_thred['Change_NP1TOT']['mean'], h_thred['Change_NP1TOT']['var'],k)\n",
    "pd_patients_all['Label_NP2PTOT'] = label_func_pos(pd_patients_all['Change_NP2PTOT'], h_thred['Change_NP2PTOT']['mean'], h_thred['Change_NP2PTOT']['var'],k)\n",
    "pd_patients_all['Label_NP3TOT'] = label_func_pos(pd_patients_all['Change_NP3TOT'], h_thred['Change_NP3TOT']['mean'], h_thred['Change_NP3TOT']['var'],k)\n",
    "pd_patients_all['Label_NP3_Axial'] = label_func_pos(pd_patients_all['Change_NP3_Axial'], h_thred['Change_NP3_Axial']['mean'], h_thred['Change_NP3_Axial']['var'],k)\n",
    "pd_patients_all['Label_NP3_Tremor'] = label_func_pos(pd_patients_all['Change_NP3_Tremor'], h_thred['Change_NP3_Tremor']['mean'], h_thred['Change_NP3_Tremor']['var'],k)\n",
    "pd_patients_all['Label_NP3_Akinetic_Rigid'] = label_func_pos(pd_patients_all['Change_NP3_Akinetic_Rigid'], h_thred['Change_NP3_Akinetic_Rigid']['mean'], h_thred['Change_NP3_Akinetic_Rigid']['var'],k)\n",
    "pd_patients_all['Label_NPTOT'] =  label_func_pos(pd_patients_all['Change_NPTOT'], h_thred['Change_NPTOT']['mean'], h_thred['Change_NPTOT']['var'],k)\n",
    "pd_patients_all['Label_ESS_TOT'] =  label_func_pos(pd_patients_all['Change_ESS_TOT'], h_thred['Change_ESS_TOT']['mean'], h_thred['Change_ESS_TOT']['var'],k)\n",
    "pd_patients_all['Label_MoCA_score'] =  label_func_neg(pd_patients_all['Change_MoCA_score'], h_thred['Change_MoCA_score']['mean'], h_thred['Change_MoCA_score']['var'],k)\n",
    "pd_patients_all['Label_NHY'] = pd_patients_all['Change_NHY'].apply(label_func_hy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_patients_all.to_csv(path+'/data/pd_12month_all_mri.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(pd_patients_all, t_label = 'Label_NHY', thred =0.8):\n",
    "\n",
    "    print('=====================================')\n",
    "    print('Train Test seperation!!!!')\n",
    "    pd_patients_all['INFODT']= pd.to_datetime(pd_patients_all['INFODT'])\n",
    "    pd_patients_all.sort_values(by='INFODT',ascending=True,inplace=True)\n",
    "    pd_patients_all.reset_index(drop=True,inplace=True)\n",
    "    m_l = pd_patients_all[t_label].mean()\n",
    "    postive_case = pd_patients_all[pd_patients_all[t_label]>0]\n",
    "    negtive_case = pd_patients_all[pd_patients_all[t_label]<=0]\n",
    "    train_all_idx = list(postive_case[:int(len(postive_case)*thred)].index)+list(negtive_case[:int(len(negtive_case)*thred)].index)\n",
    "    train_all=pd_patients_all.loc[train_all_idx]\n",
    "    test = pd_patients_all.drop(train_all_idx)\n",
    "    train_all=train_all.sample(frac=1)\n",
    "    test=test.sample(frac=1)\n",
    "    train_all_idx=train_all.index\n",
    "    test_idx=test.index\n",
    "    for label in label_tar: \n",
    "        print(label)\n",
    "        # print(\"Train:\",train_all[label].value_counts()[1]/sum(train_all[label].value_counts())) \n",
    "        print(\"Train:\",train_all[label].value_counts())\n",
    "        # print(\"test:\",test[label].value_counts()[1]/sum(test[label].value_counts()))\n",
    "        print(\"test:\",test[label].value_counts())\n",
    "    return train_all, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all, test= train_test(pd_patients_all_BLV4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "337b4bfff806d15d64b34386022e936f1b7fcc658271b29bbd7463653d5826a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
